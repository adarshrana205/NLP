{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarshrana205/NLP/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvAFTxTbG3Ja",
        "colab_type": "text"
      },
      "source": [
        "# Tokeniztion:\n",
        "####Process of splitting the input text into meaningful chunks and that chunk is called token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EXGJEmiG3Jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cab2e760-3d67-47be-82fb-39565741792e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzSrCoGOG3Ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"This is Andrew's text, isn't it?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4590qRIG3Jn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e0f6639-4328-44e8-8b81-9493ffb5e720"
      },
      "source": [
        "tokenizer = nltk.tokenize.WhitespaceTokenizer() # splits the input sentence on whitespaces\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', \"Andrew's\", 'text,', \"isn't\", 'it?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQAIXOnhG3Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa45b082-146a-45c9-d537-850a1a469b12"
      },
      "source": [
        "tokenizer = nltk.tokenize.TreebankWordTokenizer() # uses grammer rules for tokenization\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'Andrew', \"'s\", 'text', ',', 'is', \"n't\", 'it', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXv22CFcG3Jw",
        "colab_type": "code",
        "colab": {},
        "outputId": "0166da6b-509b-4c2c-bc40-da42ae8fe5ad"
      },
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'Andrew', \"'\", 's', 'text', ',', 'isn', \"'\", 't', 'it', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBeAxCCRG3J0",
        "colab_type": "text"
      },
      "source": [
        "# Token Normaliztion:\n",
        "####Same token for different forms of the word.\n",
        "# Stemming:\n",
        "####Removing and replacing the suffixes to get root form of word.\n",
        "# Lemmatization:\n",
        "####Returns base or dictionary form of word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56fw9CXBG3J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"feet wolves cats talked\"\n",
        "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
        "tokens = tokenizer.tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqnBbfXQG3J5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2feb4e7-ad5c-4ccc-e18e-98488d1cabe6"
      },
      "source": [
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feet', 'wolves', 'cats', 'talked']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVeedg-7G3J_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70d57dc9-542b-4c06-db9f-9c2f9cc8297b"
      },
      "source": [
        "stemmer = nltk.stem.PorterStemmer()\n",
        "\" \".join(stemmer.stem(token) for token in tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'feet wolv cat talk'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxSMVfAJG3KD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ae4e603-64cb-4b03-98b1-9928bb0b2326"
      },
      "source": [
        "stemmer = nltk.stem.WordNetLemmatizer()\n",
        "\" \".join(stemmer.lemmatize(token) for token in tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'foot wolf cat talked'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-81NPfP6Wom",
        "colab_type": "text"
      },
      "source": [
        "#TF-IDF\n",
        "\n",
        "#### TF: Frequency of term t in document d is called term frequency.\n",
        "#### IDF:Lets denote by capital N, total number of documents in our corpus, and our corpus is a capital D, that is the set of all our documents. Now, let's look at how many documents are there in that corpus that contain a specific term. And that is the second line and that is the size of that set that actually means the number of documents where the term appears. If you think about document frequency, then you would take that number of documents where the term appears and divide by the total number of documents, and you have a frequency of those of that term in our documents. But if you want to take inverse argument frequency then you just swap the up and down of that ratio and you take a logarithm of that and that thing, we will call inverse document frequency. So, it is just the logarithm of N over the number of documents where the term appears. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENgqwg_e6coZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGDq1HXh69Xu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "511b8697-5aef-4eb7-b13e-ae09eb80e9b3"
      },
      "source": [
        "texts = [\n",
        "    \"good movie\", \"not a good movie\", \"did not like\", \n",
        "    \"i like it\", \"good one\"\n",
        "]\n",
        "# using default tokenizer in TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names()\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>good movie</th>\n",
              "      <th>like</th>\n",
              "      <th>movie</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.577350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   good movie      like     movie       not\n",
              "0    0.707107  0.000000  0.707107  0.000000\n",
              "1    0.577350  0.000000  0.577350  0.577350\n",
              "2    0.000000  0.707107  0.000000  0.707107\n",
              "3    0.000000  1.000000  0.000000  0.000000\n",
              "4    0.000000  0.000000  0.000000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFQB4eUl9Fyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}